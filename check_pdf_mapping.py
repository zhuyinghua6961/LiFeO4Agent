#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€æŸ¥ DOI åˆ° PDF æ˜ å°„çš„ä¸€è‡´æ€§
"""
import json
import os
from pathlib import Path
from collections import defaultdict

# è·¯å¾„é…ç½®
MAPPING_FILE = "/Users/zhuyinghua/Desktop/agent/main/doi_to_pdf_mapping.json"
PAPERS_DIR = "/Users/zhuyinghua/Desktop/agent/main/papers"

def load_mapping():
    """åŠ è½½DOIæ˜ å°„æ–‡ä»¶"""
    with open(MAPPING_FILE, 'r', encoding='utf-8') as f:
        return json.load(f)

def get_pdf_files():
    """è·å–papersç›®å½•ä¸‹çš„æ‰€æœ‰PDFæ–‡ä»¶"""
    papers_path = Path(PAPERS_DIR)
    if not papers_path.exists():
        print(f"âŒ papersç›®å½•ä¸å­˜åœ¨: {PAPERS_DIR}")
        return []
    
    pdf_files = list(papers_path.glob("*.pdf"))
    return [f.name for f in pdf_files]

def check_mapping_consistency():
    """æ£€æŸ¥æ˜ å°„ä¸€è‡´æ€§"""
    print("=" * 80)
    print("ğŸ“Š DOIåˆ°PDFæ˜ å°„ä¸€è‡´æ€§æ£€æŸ¥")
    print("=" * 80)
    
    # åŠ è½½æ˜ å°„
    print("\n1. åŠ è½½DOIæ˜ å°„æ–‡ä»¶...")
    mapping = load_mapping()
    print(f"   æ˜ å°„æ–‡ä»¶ä¸­çš„DOIæ•°é‡: {len(mapping)}")
    
    # è·å–å®é™…PDFæ–‡ä»¶
    print("\n2. æ‰«æpapersç›®å½•...")
    actual_pdfs = set(get_pdf_files())
    print(f"   å®é™…PDFæ–‡ä»¶æ•°é‡: {len(actual_pdfs)}")
    
    # æ˜ å°„ä¸­çš„PDFæ–‡ä»¶
    mapped_pdfs = set(mapping.values())
    print(f"   æ˜ å°„ä¸­å¼•ç”¨çš„PDFæ•°é‡: {len(mapped_pdfs)}")
    
    print("\n" + "=" * 80)
    print("ğŸ“‹ ä¸€è‡´æ€§åˆ†æ")
    print("=" * 80)
    
    # 1. æ˜ å°„ä¸­æœ‰ä½†å®é™…ä¸å­˜åœ¨çš„PDF
    missing_pdfs = mapped_pdfs - actual_pdfs
    if missing_pdfs:
        print(f"\nâŒ æ˜ å°„ä¸­å¼•ç”¨ä½†å®é™…ä¸å­˜åœ¨çš„PDFæ–‡ä»¶ ({len(missing_pdfs)}ä¸ª):")
        for i, pdf in enumerate(sorted(missing_pdfs)[:20], 1):
            # æ‰¾å‡ºå¼•ç”¨è¿™ä¸ªPDFçš„DOI
            dois = [doi for doi, p in mapping.items() if p == pdf]
            print(f"   {i}. {pdf}")
            print(f"      å…³è”DOI: {', '.join(dois[:3])}{'...' if len(dois) > 3 else ''}")
        if len(missing_pdfs) > 20:
            print(f"   ... è¿˜æœ‰ {len(missing_pdfs) - 20} ä¸ªæœªæ˜¾ç¤º")
    else:
        print("\nâœ… æ‰€æœ‰æ˜ å°„çš„PDFæ–‡ä»¶éƒ½å­˜åœ¨")
    
    # 2. å®é™…å­˜åœ¨ä½†æœªåœ¨æ˜ å°„ä¸­çš„PDF
    unmapped_pdfs = actual_pdfs - mapped_pdfs
    if unmapped_pdfs:
        print(f"\nâš ï¸  å­˜åœ¨ä½†æœªåœ¨æ˜ å°„ä¸­çš„PDFæ–‡ä»¶ ({len(unmapped_pdfs)}ä¸ª):")
        for i, pdf in enumerate(sorted(unmapped_pdfs)[:20], 1):
            print(f"   {i}. {pdf}")
        if len(unmapped_pdfs) > 20:
            print(f"   ... è¿˜æœ‰ {len(unmapped_pdfs) - 20} ä¸ªæœªæ˜¾ç¤º")
    else:
        print("\nâœ… æ‰€æœ‰PDFæ–‡ä»¶éƒ½å·²åœ¨æ˜ å°„ä¸­")
    
    # 3. å¤šä¸ªDOIæ˜ å°„åˆ°åŒä¸€ä¸ªPDF
    print("\n" + "=" * 80)
    print("ğŸ”„ é‡å¤æ˜ å°„æ£€æŸ¥")
    print("=" * 80)
    
    pdf_to_dois = defaultdict(list)
    for doi, pdf in mapping.items():
        pdf_to_dois[pdf].append(doi)
    
    duplicate_mappings = {pdf: dois for pdf, dois in pdf_to_dois.items() if len(dois) > 1}
    if duplicate_mappings:
        print(f"\nâš ï¸  å¤šä¸ªDOIæ˜ å°„åˆ°åŒä¸€ä¸ªPDFçš„æƒ…å†µ ({len(duplicate_mappings)}ä¸ªPDF):")
        for i, (pdf, dois) in enumerate(sorted(duplicate_mappings.items())[:10], 1):
            print(f"   {i}. {pdf}")
            print(f"      å…³è” {len(dois)} ä¸ªDOI: {', '.join(dois[:5])}{'...' if len(dois) > 5 else ''}")
        if len(duplicate_mappings) > 10:
            print(f"   ... è¿˜æœ‰ {len(duplicate_mappings) - 10} ä¸ªæœªæ˜¾ç¤º")
    else:
        print("\nâœ… æ²¡æœ‰é‡å¤æ˜ å°„")
    
    # 4. ç»Ÿè®¡æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š ç»Ÿè®¡æ€»ç»“")
    print("=" * 80)
    
    valid_mappings = len([doi for doi, pdf in mapping.items() if pdf in actual_pdfs])
    invalid_mappings = len(mapping) - valid_mappings
    
    print(f"\n   DOIæ€»æ•°: {len(mapping)}")
    print(f"   æœ‰æ•ˆæ˜ å°„: {valid_mappings} ({valid_mappings/len(mapping)*100:.1f}%)")
    print(f"   å¤±æ•ˆæ˜ å°„: {invalid_mappings} ({invalid_mappings/len(mapping)*100:.1f}%)")
    print(f"   å®é™…PDFæ–‡ä»¶: {len(actual_pdfs)}")
    print(f"   æœªæ˜ å°„çš„PDF: {len(unmapped_pdfs)}")
    print(f"   è¦†ç›–ç‡: {len(mapped_pdfs & actual_pdfs) / len(actual_pdfs) * 100:.1f}%")
    
    # 5. å»ºè®®
    print("\n" + "=" * 80)
    print("ğŸ’¡ å»ºè®®")
    print("=" * 80)
    
    if missing_pdfs:
        print(f"\n   1. æ¸…ç† {len(missing_pdfs)} ä¸ªæ— æ•ˆçš„æ˜ å°„æ¡ç›®")
    if unmapped_pdfs:
        print(f"   2. ä¸º {len(unmapped_pdfs)} ä¸ªæœªæ˜ å°„çš„PDFæ–‡ä»¶æ·»åŠ DOIæ˜ å°„")
    if duplicate_mappings:
        print(f"   3. æ£€æŸ¥ {len(duplicate_mappings)} ä¸ªé‡å¤æ˜ å°„,ç¡®è®¤æ˜¯å¦åˆç†")
    
    if not missing_pdfs and not unmapped_pdfs:
        print("\n   âœ… æ˜ å°„æ–‡ä»¶ä¸å®é™…æ–‡ä»¶å®Œå…¨ä¸€è‡´!")
    
    print("\n" + "=" * 80)

if __name__ == "__main__":
    try:
        check_mapping_consistency()
    except FileNotFoundError as e:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {e}")
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
