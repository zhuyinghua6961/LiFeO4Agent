#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é‡å»º DOI åˆ° PDF æ˜ å°„æ–‡ä»¶
ä» PDF æ–‡ä»¶ä¸­æå– DOI ä¿¡æ¯
"""
import json
import re
import os
from pathlib import Path
from typing import Dict, List, Optional
import PyPDF2
from tqdm import tqdm
import concurrent.futures

# è·¯å¾„é…ç½®
PAPERS_DIR = "/Users/zhuyinghua/Desktop/agent/main/papers"
OUTPUT_FILE = "/Users/zhuyinghua/Desktop/agent/main/doi_to_pdf_mapping_new.json"
BACKUP_FILE = "/Users/zhuyinghua/Desktop/agent/main/doi_to_pdf_mapping_backup.json"

# DOI æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
DOI_PATTERNS = [
    r'10\.\d{4,}/[^\s\>\]\)]+',  # æ ‡å‡†DOIæ ¼å¼
    r'doi:\s*10\.\d{4,}/[^\s\>\]\)]+',  # doi: å‰ç¼€
    r'DOI:\s*10\.\d{4,}/[^\s\>\]\)]+',  # DOI: å‰ç¼€
]

def extract_doi_from_text(text: str) -> Optional[str]:
    """ä»æ–‡æœ¬ä¸­æå–DOI"""
    if not text:
        return None
    
    # å°è¯•æ‰€æœ‰æ¨¡å¼
    for pattern in DOI_PATTERNS:
        matches = re.findall(pattern, text, re.IGNORECASE)
        if matches:
            # æ¸…ç†DOI
            doi = matches[0].lower()
            doi = doi.replace('doi:', '').replace('DOI:', '').strip()
            # ç§»é™¤æœ«å°¾çš„æ ‡ç‚¹ç¬¦å·
            doi = re.sub(r'[.,;:\)\]>]+$', '', doi)
            return doi
    
    return None

def extract_doi_from_filename(filename: str) -> Optional[str]:
    """ä»æ–‡ä»¶åä¸­å°è¯•æå–DOI"""
    # ç§»é™¤ .pdf æ‰©å±•å
    name = filename.replace('.pdf', '')
    
    # å°è¯•åŒ¹é…æ ‡å‡†DOIæ¨¡å¼
    match = re.search(r'10\.\d{4,}[/_][^\s]+', name)
    if match:
        doi = match.group(0)
        # å°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºæ–œæ 
        doi = doi.replace('_', '/')
        return doi
    
    return None

def extract_doi_from_pdf(pdf_path: Path) -> Optional[str]:
    """ä»PDFæ–‡ä»¶ä¸­æå–DOI"""
    try:
        # é¦–å…ˆå°è¯•ä»æ–‡ä»¶åæå–
        doi_from_name = extract_doi_from_filename(pdf_path.name)
        if doi_from_name:
            return doi_from_name
        
        # å°è¯•ä»PDFå†…å®¹æå–
        with open(pdf_path, 'rb') as f:
            try:
                reader = PyPDF2.PdfReader(f)
                
                # å°è¯•ä»å…ƒæ•°æ®æå–
                if reader.metadata:
                    for key in ['/Subject', '/Title', '/Keywords']:
                        if key in reader.metadata:
                            doi = extract_doi_from_text(str(reader.metadata[key]))
                            if doi:
                                return doi
                
                # ä»å‰3é¡µæå–æ–‡æœ¬
                num_pages = min(3, len(reader.pages))
                for i in range(num_pages):
                    try:
                        text = reader.pages[i].extract_text()
                        if text:
                            doi = extract_doi_from_text(text)
                            if doi:
                                return doi
                    except:
                        continue
            except Exception as e:
                pass
        
        return None
    except Exception as e:
        return None

def process_single_pdf(pdf_path: Path) -> tuple:
    """å¤„ç†å•ä¸ªPDFæ–‡ä»¶"""
    doi = extract_doi_from_pdf(pdf_path)
    return (pdf_path.name, doi)

def build_mapping(papers_dir: str, use_parallel: bool = True) -> Dict[str, str]:
    """æ„å»ºDOIåˆ°PDFçš„æ˜ å°„"""
    papers_path = Path(papers_dir)
    pdf_files = list(papers_path.glob("*.pdf"))
    
    print(f"ğŸ“ æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    print(f"ğŸ” å¼€å§‹æå–DOIä¿¡æ¯...")
    
    mapping = {}
    failed = []
    
    if use_parallel:
        # å¹¶è¡Œå¤„ç†
        with concurrent.futures.ThreadPoolExecutor(max_workers=8) as executor:
            futures = {executor.submit(process_single_pdf, pdf): pdf for pdf in pdf_files}
            
            with tqdm(total=len(pdf_files), desc="å¤„ç†PDF") as pbar:
                for future in concurrent.futures.as_completed(futures):
                    filename, doi = future.result()
                    if doi:
                        mapping[doi] = filename
                    else:
                        failed.append(filename)
                    pbar.update(1)
    else:
        # ä¸²è¡Œå¤„ç†
        for pdf_path in tqdm(pdf_files, desc="å¤„ç†PDF"):
            filename, doi = process_single_pdf(pdf_path)
            if doi:
                mapping[doi] = filename
            else:
                failed.append(filename)
    
    print(f"\nâœ… æˆåŠŸæå–: {len(mapping)} ä¸ªDOI")
    print(f"âŒ å¤±è´¥: {len(failed)} ä¸ªæ–‡ä»¶")
    
    return mapping, failed

def save_mapping(mapping: Dict[str, str], output_file: str):
    """ä¿å­˜æ˜ å°„åˆ°JSONæ–‡ä»¶"""
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(mapping, f, ensure_ascii=False, indent=2)
    print(f"ğŸ’¾ æ˜ å°„æ–‡ä»¶å·²ä¿å­˜: {output_file}")

def backup_old_mapping(old_file: str, backup_file: str):
    """å¤‡ä»½æ—§çš„æ˜ å°„æ–‡ä»¶"""
    if os.path.exists(old_file):
        import shutil
        shutil.copy2(old_file, backup_file)
        print(f"ğŸ“¦ æ—§æ˜ å°„æ–‡ä»¶å·²å¤‡ä»½: {backup_file}")

def analyze_results(mapping: Dict[str, str], failed: List[str]):
    """åˆ†æç»“æœç»Ÿè®¡"""
    print("\n" + "="*80)
    print("ğŸ“Š ç»Ÿè®¡æŠ¥å‘Š")
    print("="*80)
    
    # åŸºæœ¬ç»Ÿè®¡
    total = len(mapping) + len(failed)
    success_rate = len(mapping) / total * 100 if total > 0 else 0
    
    print(f"\næ€»è®¡å¤„ç†: {total} ä¸ªPDFæ–‡ä»¶")
    print(f"æˆåŠŸæå–DOI: {len(mapping)} ä¸ª ({success_rate:.1f}%)")
    print(f"æœªèƒ½æå–DOI: {len(failed)} ä¸ª ({100-success_rate:.1f}%)")
    
    # æ£€æŸ¥é‡å¤
    from collections import Counter
    pdf_counts = Counter(mapping.values())
    duplicates = {pdf: count for pdf, count in pdf_counts.items() if count > 1}
    
    if duplicates:
        print(f"\nâš ï¸  é‡å¤æ˜ å°„: {len(duplicates)} ä¸ªPDFè¢«å¤šä¸ªDOIå¼•ç”¨")
        print("å‰5ä¸ªé‡å¤æœ€å¤šçš„PDF:")
        for pdf, count in sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:5]:
            print(f"  - {pdf}: {count} ä¸ªDOI")
    
    # æ˜¾ç¤ºå¤±è´¥æ ·ä¾‹
    if failed:
        print(f"\nâŒ æœªèƒ½æå–DOIçš„æ–‡ä»¶ç¤ºä¾‹ (å‰10ä¸ª):")
        for f in failed[:10]:
            print(f"  - {f}")
        if len(failed) > 10:
            print(f"  ... è¿˜æœ‰ {len(failed)-10} ä¸ª")

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ”¨ é‡å»º DOI åˆ° PDF æ˜ å°„æ–‡ä»¶")
    print("="*80)
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import PyPDF2
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–: PyPDF2")
        print("è¯·è¿è¡Œ: pip install PyPDF2")
        return
    
    try:
        import tqdm
    except ImportError:
        print("âŒ ç¼ºå°‘ä¾èµ–: tqdm")
        print("è¯·è¿è¡Œ: pip install tqdm")
        return
    
    # å¤‡ä»½æ—§æ–‡ä»¶
    old_mapping_file = "/Users/zhuyinghua/Desktop/agent/main/doi_to_pdf_mapping.json"
    backup_old_mapping(old_mapping_file, BACKUP_FILE)
    
    # æ„å»ºæ˜ å°„
    mapping, failed = build_mapping(PAPERS_DIR, use_parallel=True)
    
    # ä¿å­˜ç»“æœ
    save_mapping(mapping, OUTPUT_FILE)
    
    # ä¿å­˜å¤±è´¥åˆ—è¡¨
    failed_file = "/Users/zhuyinghua/Desktop/agent/main/failed_pdf_extraction.txt"
    if failed:
        with open(failed_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(failed))
        print(f"ğŸ“ å¤±è´¥åˆ—è¡¨å·²ä¿å­˜: {failed_file}")
    
    # åˆ†æç»“æœ
    analyze_results(mapping, failed)
    
    print("\n" + "="*80)
    print("âœ… å®Œæˆ!")
    print("="*80)
    print(f"\næ–°æ˜ å°„æ–‡ä»¶: {OUTPUT_FILE}")
    print(f"æ—§æ˜ å°„å¤‡ä»½: {BACKUP_FILE}")
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"1. æ£€æŸ¥æ–°æ˜ å°„æ–‡ä»¶: {OUTPUT_FILE}")
    print(f"2. å¦‚æœæ»¡æ„,æ›¿æ¢æ—§æ–‡ä»¶:")
    print(f"   mv {OUTPUT_FILE} {old_mapping_file}")

if __name__ == "__main__":
    main()
