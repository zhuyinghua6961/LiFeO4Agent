"""
éªŒè¯ JSON è¾“å‡ºæ ¼å¼

æ£€æŸ¥ç”Ÿæˆçš„ JSON æ–‡ä»¶æ˜¯å¦ç¬¦åˆè®¾è®¡æ–‡æ¡£çš„è¦æ±‚
"""

import json
from pathlib import Path


def validate_json_output(json_path: Path):
    """éªŒè¯ JSON è¾“å‡ºæ ¼å¼"""
    
    print(f"éªŒè¯ JSON æ–‡ä»¶: {json_path.name}")
    print("=" * 80)
    
    # è¯»å– JSON æ–‡ä»¶
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    errors = []
    warnings = []
    
    # 1. æ£€æŸ¥é¡¶å±‚å­—æ®µ
    print("\n1. æ£€æŸ¥é¡¶å±‚å­—æ®µ...")
    required_top_fields = ["source_file", "document_title", "processing_timestamp", 
                          "sentences", "tables", "processing_stats"]
    
    for field in required_top_fields:
        if field not in data:
            errors.append(f"ç¼ºå°‘é¡¶å±‚å­—æ®µ: {field}")
        else:
            print(f"  âœ“ {field}")
    
    # 2. æ£€æŸ¥å¥å­æ¡ç›®
    print("\n2. æ£€æŸ¥å¥å­æ¡ç›®...")
    if "sentences" in data:
        sentences = data["sentences"]
        print(f"  - å¥å­æ€»æ•°: {len(sentences)}")
        
        # æ£€æŸ¥å‰å‡ ä¸ªå¥å­çš„æ ¼å¼
        for i, sent in enumerate(sentences[:5]):
            required_sent_fields = ["id", "text", "keywords", "location", "sentence_type"]
            for field in required_sent_fields:
                if field not in sent:
                    errors.append(f"å¥å­ {i} ç¼ºå°‘å­—æ®µ: {field}")
            
            # æ£€æŸ¥ location å­—æ®µ
            if "location" in sent:
                location = sent["location"]
                required_loc_fields = ["section_path", "section_id", "paragraph_index", 
                                      "sentence_index", "line_range", "page_reference"]
                for field in required_loc_fields:
                    if field not in location:
                        errors.append(f"å¥å­ {i} çš„ location ç¼ºå°‘å­—æ®µ: {field}")
        
        print(f"  âœ“ æ£€æŸ¥äº†å‰ 5 ä¸ªå¥å­çš„æ ¼å¼")
        
        # æ£€æŸ¥ ID å”¯ä¸€æ€§
        ids = [s["id"] for s in sentences]
        if len(ids) != len(set(ids)):
            errors.append("å¥å­ ID ä¸å”¯ä¸€")
        else:
            print(f"  âœ“ æ‰€æœ‰å¥å­ ID å”¯ä¸€")
    
    # 3. æ£€æŸ¥è¡¨æ ¼æ¡ç›®
    print("\n3. æ£€æŸ¥è¡¨æ ¼æ¡ç›®...")
    if "tables" in data:
        tables = data["tables"]
        print(f"  - è¡¨æ ¼æ€»æ•°: {len(tables)}")
        
        for i, table in enumerate(tables):
            required_table_fields = ["id", "content", "keywords", "location", "metadata"]
            for field in required_table_fields:
                if field not in table:
                    errors.append(f"è¡¨æ ¼ {i} ç¼ºå°‘å­—æ®µ: {field}")
            
            # æ£€æŸ¥ metadata å­—æ®µ
            if "metadata" in table:
                metadata = table["metadata"]
                required_meta_fields = ["rows", "columns", "headers"]
                for field in required_meta_fields:
                    if field not in metadata:
                        errors.append(f"è¡¨æ ¼ {i} çš„ metadata ç¼ºå°‘å­—æ®µ: {field}")
        
        print(f"  âœ“ æ£€æŸ¥äº†æ‰€æœ‰è¡¨æ ¼çš„æ ¼å¼")
    
    # 4. æ£€æŸ¥å¤„ç†ç»Ÿè®¡
    print("\n4. æ£€æŸ¥å¤„ç†ç»Ÿè®¡...")
    if "processing_stats" in data:
        stats = data["processing_stats"]
        required_stats_fields = ["total_sentences", "total_tables", "original_line_count",
                                "cleaned_line_count", "removed_images", 
                                "removed_metadata_lines", "converted_html_tags"]
        
        for field in required_stats_fields:
            if field not in stats:
                errors.append(f"processing_stats ç¼ºå°‘å­—æ®µ: {field}")
            else:
                print(f"  âœ“ {field}: {stats[field]}")
    
    # 5. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§
    print("\n5. æ£€æŸ¥æ•°æ®ä¸€è‡´æ€§...")
    if "sentences" in data and "processing_stats" in data:
        if len(data["sentences"]) != data["processing_stats"]["total_sentences"]:
            warnings.append(f"å¥å­æ•°é‡ä¸ä¸€è‡´: å®é™… {len(data['sentences'])}, ç»Ÿè®¡ {data['processing_stats']['total_sentences']}")
        else:
            print(f"  âœ“ å¥å­æ•°é‡ä¸€è‡´")
    
    if "tables" in data and "processing_stats" in data:
        if len(data["tables"]) != data["processing_stats"]["total_tables"]:
            warnings.append(f"è¡¨æ ¼æ•°é‡ä¸ä¸€è‡´: å®é™… {len(data['tables'])}, ç»Ÿè®¡ {data['processing_stats']['total_tables']}")
        else:
            print(f"  âœ“ è¡¨æ ¼æ•°é‡ä¸€è‡´")
    
    # 6. æ£€æŸ¥ç¼–ç 
    print("\n6. æ£€æŸ¥ç¼–ç ...")
    # æ£€æŸ¥æ˜¯å¦æœ‰ç§‘å­¦è®°å·
    has_subscript = any("_{" in s["text"] for s in data.get("sentences", []))
    has_superscript = any("^{" in s["text"] for s in data.get("sentences", []))
    
    if has_subscript:
        print(f"  âœ“ æ­£ç¡®ä¿ç•™ä¸‹æ ‡è®°å·")
    if has_superscript:
        print(f"  âœ“ æ­£ç¡®ä¿ç•™ä¸Šæ ‡è®°å·")
    
    # 7. è¾“å‡ºç»“æœ
    print("\n" + "=" * 80)
    print("éªŒè¯ç»“æœ:")
    
    if errors:
        print(f"\nâŒ å‘ç° {len(errors)} ä¸ªé”™è¯¯:")
        for error in errors:
            print(f"  - {error}")
    else:
        print("\nâœ… æ²¡æœ‰å‘ç°é”™è¯¯")
    
    if warnings:
        print(f"\nâš ï¸  å‘ç° {len(warnings)} ä¸ªè­¦å‘Š:")
        for warning in warnings:
            print(f"  - {warning}")
    else:
        print("âœ… æ²¡æœ‰å‘ç°è­¦å‘Š")
    
    if not errors and not warnings:
        print("\nğŸ‰ JSON æ ¼å¼å®Œå…¨ç¬¦åˆè®¾è®¡æ–‡æ¡£è¦æ±‚ï¼")
    
    return len(errors) == 0


def main():
    """ä¸»å‡½æ•°"""
    
    json_path = Path("qwen2.5B/output/Enhanced-properties-of-LiFePO4-C-cathode-materials-_2014_Materials-Chemistry_sentences.json")
    
    if not json_path.exists():
        print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {json_path}")
        return
    
    is_valid = validate_json_output(json_path)
    
    if is_valid:
        print("\nâœ“ éªŒè¯é€šè¿‡ï¼")
    else:
        print("\nâœ— éªŒè¯å¤±è´¥ï¼")


if __name__ == "__main__":
    main()
