"""
APIè·¯ç”±å®šä¹‰
RESTful APIç«¯ç‚¹
"""
import json
import logging
from typing import Dict, Any, Optional
from flask import Blueprint, request, jsonify
from flask_cors import CORS

from backend.config.settings import settings
from backend.services.llm_service import LLMService
from backend.services.neo4j_service import Neo4jService
from backend.services.vector_service import VectorService
from backend.agents.experts import RouterExpert, QueryExpert, SemanticExpert
from backend.models import (
    QueryRequest, RouteRequest, SearchParams,
    QueryResponse, RouteResponse, SearchResponse,
    ErrorResponse
)

logger = logging.getLogger(__name__)

# åˆ›å»ºè“å›¾
api = Blueprint('api', __name__, url_prefix='/api')

# å…¨å±€æœåŠ¡å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰
_llm_service: Optional[LLMService] = None
_neo4j_service: Optional[Neo4jService] = None
_vector_service: Optional[VectorService] = None
_router_expert: Optional[RouterExpert] = None
_query_expert: Optional[QueryExpert] = None
_semantic_expert: Optional[SemanticExpert] = None


def get_services():
    """è·å–æ‰€æœ‰æœåŠ¡å®ä¾‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _llm_service, _neo4j_service, _vector_service
    global _router_expert, _query_expert, _semantic_expert
    
    if _llm_service is None:
        _llm_service = LLMService(
            api_key=settings.llm_api_key,
            model=settings.llm_model
        )
    
    if _neo4j_service is None:
        _neo4j_service = Neo4jService()
    
    if _vector_service is None:
        from backend.repositories.vector_repository import VectorRepository, CommunityVectorRepository
        vector_repo = VectorRepository()
        community_repo = CommunityVectorRepository()
        _vector_service = VectorService(
            vector_repo=vector_repo,
            community_repo=community_repo,
            llm_service=_llm_service
        )
    
    if _router_expert is None:
        _router_expert = RouterExpert(llm_service=_llm_service)
    
    if _query_expert is None:
        _query_expert = QueryExpert(
            neo4j_service=_neo4j_service,
            llm_service=_llm_service
        )
    
    if _semantic_expert is None:
        from backend.repositories.vector_repository import VectorRepository
        vector_repo = VectorRepository()
        _semantic_expert = SemanticExpert(
            vector_repo=vector_repo,
            llm_service=_llm_service
        )
    
    return {
        'llm': _llm_service,
        'neo4j': _neo4j_service,
        'vector': _vector_service,
        'router': _router_expert,
        'query': _query_expert,
        'semantic': _semantic_expert
    }


# ============== é—®ç­”æµå¼ç«¯ç‚¹ (RAG æ¨¡å¼) ==============

@api.route('/ask_stream', methods=['POST'])
def ask_stream():
    """
    é—®ç­”æµå¼æ¥å£ (SSEæ ¼å¼) - ä½¿ç”¨ IntegratedAgent
    
    æµç¨‹:
    1. ç”¨æˆ·æé—®
    2. IntegratedAgent è‡ªåŠ¨è·¯ç”±åˆ°åˆé€‚çš„ä¸“å®¶
    3. ä¸“å®¶æ‰§è¡ŒæŸ¥è¯¢å¹¶åˆæˆç­”æ¡ˆ
    4. æµå¼è¿”å›ç»“æœ
    5. (å¯é€‰) ä¿å­˜å¯¹è¯åˆ°æŒä¹…åŒ–å­˜å‚¨
    
    è¯·æ±‚ä½“:
    {
        "question": "ç£·é…¸é“é”‚çš„ç”µå‹æ˜¯å¤šå°‘",
        "chat_history": [],
        "user_id": 1 (å¯é€‰),
        "conversation_id": 123 (å¯é€‰)
    }
    """
    data = request.get_json()
    if not data:
        return jsonify(ErrorResponse(error='è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º', code='INVALID_REQUEST').to_dict()), 400
    
    question = data.get('question', '')
    if not question:
        return jsonify(ErrorResponse(error='é—®é¢˜ä¸èƒ½ä¸ºç©º', code='VALIDATION_ERROR').to_dict()), 400
    
    # è·å–å¯é€‰çš„æŒä¹…åŒ–å‚æ•°
    user_id = data.get('user_id')
    conversation_id = data.get('conversation_id')
    
    logger.info(f"ğŸ” æ”¶åˆ°é—®é¢˜: {question}, user_id={user_id}, conversation_id={conversation_id}")
    
    def generate():
        nonlocal conversation_id  # å£°æ˜ä½¿ç”¨å¤–å±‚çš„ conversation_id å˜é‡
        
        # ç”¨äºæ”¶é›†AIå›å¤çš„å®Œæ•´æ•°æ®
        collected_steps = []
        collected_content = ""
        collected_references = []
        expert_used = None
        query_mode = None
        
        try:
            # è·å– IntegratedAgent
            from backend.agents.integrated_agent import get_integrated_agent
            integrated_agent = get_integrated_agent()
            
            # å¦‚æœæä¾›äº†user_idä½†æ²¡æœ‰conversation_idï¼Œè‡ªåŠ¨åˆ›å»ºæ–°å¯¹è¯
            if user_id and not conversation_id:
                try:
                    from backend.services.conversation_service import ConversationService
                    conv_service = ConversationService()
                    result = conv_service.create_conversation(user_id, "æ–°å¯¹è¯")
                    conversation_id = result['conversation_id']
                    logger.info(f"è‡ªåŠ¨åˆ›å»ºæ–°å¯¹è¯: conversation_id={conversation_id}")
                except Exception as e:
                    logger.warning(f"è‡ªåŠ¨åˆ›å»ºå¯¹è¯å¤±è´¥: {e}")
            
            # å¦‚æœå¯ç”¨æŒä¹…åŒ–ï¼Œä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            if user_id and conversation_id:
                try:
                    from backend.services.conversation_service import ConversationService
                    conv_service = ConversationService()
                    user_message = {
                        'role': 'user',
                        'content': question,
                        'steps': [],
                        'references': []
                    }
                    conv_service.add_message(conversation_id, user_id, user_message)
                    logger.info(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯æˆåŠŸ: conversation_id={conversation_id}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å¤±è´¥: {e}")
            
            # å‘é€å¼€å§‹ä¿¡å·
            start_data = json.dumps({'type': 'start', 'message': 'å¼€å§‹å¤„ç†é—®é¢˜'}, ensure_ascii=False)
            yield f"data: {start_data}\n\n"
            
            # ä½¿ç”¨ IntegratedAgent æµå¼æŸ¥è¯¢
            for chunk in integrated_agent.query_stream(question):
                # æ”¶é›†æ•°æ®ç”¨äºæŒä¹…åŒ–
                if chunk.get('type') == 'step':
                    collected_steps.append({
                        'step': chunk.get('step'),
                        'message': chunk.get('message'),
                        'status': chunk.get('status'),
                        'data': chunk.get('data'),
                        'error': chunk.get('error')
                    })
                elif chunk.get('type') == 'content':
                    collected_content += chunk.get('content', '')
                elif chunk.get('type') == 'done':
                    collected_references = chunk.get('references', [])
                    if chunk.get('metadata'):
                        expert_used = chunk.get('metadata', {}).get('expert')
                
                # æµå¼è¾“å‡º
                chunk_data = json.dumps(chunk, ensure_ascii=False)
                yield f"data: {chunk_data}\n\n"
            
            # å¦‚æœå¯ç”¨æŒä¹…åŒ–ï¼Œä¿å­˜AIå›å¤
            if user_id and conversation_id and collected_content:
                try:
                    from backend.services.conversation_service import ConversationService
                    conv_service = ConversationService()
                    
                    # ç¡®å®šæŸ¥è¯¢æ¨¡å¼
                    if expert_used == 'neo4j':
                        query_mode = 'çŸ¥è¯†å›¾è°±'
                    elif expert_used == 'community':
                        query_mode = 'ç¤¾åŒºåˆ†æ'
                    else:
                        query_mode = 'æ–‡çŒ®æ£€ç´¢'
                    
                    ai_message = {
                        'role': 'assistant',
                        'content': collected_content,
                        'queryMode': query_mode,
                        'expert': expert_used,
                        'steps': collected_steps,
                        'references': collected_references
                    }
                    conv_service.add_message(conversation_id, user_id, ai_message)
                    logger.info(f"ä¿å­˜AIå›å¤æˆåŠŸ: conversation_id={conversation_id}, steps={len(collected_steps)}")
                except Exception as e:
                    logger.warning(f"ä¿å­˜AIå›å¤å¤±è´¥: {e}")
            
            # å‘é€å®Œæˆä¿¡å·
            done_data = json.dumps({'type': 'done', 'message': 'å›ç­”å®Œæˆ'}, ensure_ascii=False)
            yield f"data: {done_data}\n\n"
            
        except Exception as e:
            logger.error(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}", exc_info=True)
            error_data = json.dumps({
                'type': 'error',
                'error': str(e),
                'message': 'å¤„ç†é—®é¢˜æ—¶å‘ç”Ÿé”™è¯¯'
            }, ensure_ascii=False)
            yield f"data: {error_data}\n\n"
    
    return generate(), {'Content-Type': 'text/event-stream', 'Cache-Control': 'no-cache', 'X-Accel-Buffering': 'no'}


# ============== PDF æ–‡ä»¶æœåŠ¡ ==============

@api.route('/pdf/<path:filename>', methods=['GET'])
def serve_pdf(filename):
    """æä¾› PDF æ–‡ä»¶è®¿é—® - é€šè¿‡DOIæ˜ å°„æŸ¥æ‰¾å®é™…PDFæ–‡ä»¶"""
    from flask import send_from_directory
    import os
    import json
    
    logger.info(f"ğŸ“„ æ”¶åˆ°PDFè¯·æ±‚: {filename}")
    
    # ä½¿ç”¨ settings ä¸­é…ç½®çš„è·¯å¾„
    from backend.config.settings import settings
    
    pdf_dir = settings.papers_dir
    mapping_file = settings.doi_to_pdf_mapping
    
    logger.debug(f"   PDFç›®å½•: {pdf_dir}")
    logger.debug(f"   æ˜ å°„æ–‡ä»¶: {mapping_file}")
    
    # ä»filenameæå–DOI
    doi = filename.replace('.pdf', '').replace('_', '/')
    logger.info(f"   æå–DOI: {doi}")
    
    # å°è¯•é€šè¿‡DOIæ˜ å°„æŸ¥æ‰¾å®é™…æ–‡ä»¶å
    real_filename = None
    if os.path.exists(mapping_file):
        try:
            with open(mapping_file, 'r', encoding='utf-8') as f:
                doi_mapping = json.load(f)
                logger.debug(f"   æ˜ å°„æ–‡ä»¶åŒ…å« {len(doi_mapping)} ä¸ªDOI")
                if doi in doi_mapping:
                    real_filename = doi_mapping[doi]
                    logger.info(f"   âœ… é€šè¿‡æ˜ å°„æ‰¾åˆ°: {doi} -> {real_filename}")
                else:
                    logger.warning(f"   âš ï¸ æ˜ å°„ä¸­æœªæ‰¾åˆ°DOI: {doi}")
        except Exception as e:
            logger.error(f"   âŒ è¯»å–æ˜ å°„æ–‡ä»¶å¤±è´¥: {e}")
    else:
        logger.warning(f"   âš ï¸ æ˜ å°„æ–‡ä»¶ä¸å­˜åœ¨: {mapping_file}")
    
    # å¦‚æœæ‰¾åˆ°æ˜ å°„ï¼Œä½¿ç”¨çœŸå®æ–‡ä»¶å
    if real_filename:
        pdf_path = os.path.join(pdf_dir, real_filename)
        logger.debug(f"   æ£€æŸ¥æ˜ å°„æ–‡ä»¶è·¯å¾„: {pdf_path}")
        if os.path.exists(pdf_path):
            logger.info(f"   âœ… è¿”å›PDFæ–‡ä»¶: {real_filename}")
            return send_from_directory(pdf_dir, real_filename)
        else:
            logger.warning(f"   âš ï¸ æ˜ å°„çš„PDFæ–‡ä»¶ä¸å­˜åœ¨: {real_filename}")
    
    # å¦‚æœæ²¡æœ‰æ˜ å°„æˆ–æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ç›´æ¥ç”¨filenameæŸ¥æ‰¾
    pdf_path = os.path.join(pdf_dir, filename)
    logger.debug(f"   å°è¯•ç›´æ¥è®¿é—®: {pdf_path}")
    if os.path.exists(pdf_path):
        logger.info(f"   âœ… ç›´æ¥æ‰¾åˆ°PDF: {filename}")
        return send_from_directory(pdf_dir, filename)
    
    # éƒ½æ‰¾ä¸åˆ°ï¼Œè¿”å›404
    logger.error(f"   âŒ PDFæ–‡ä»¶æœªæ‰¾åˆ°: DOI={doi}, filename={filename}")
    return jsonify({
        'error': 'PDF_NOT_FOUND',
        'message': 'æœ¬åœ°PDFæ–‡ä»¶ä¸å­˜åœ¨',
        'doi': doi,
        'filename': filename,
        'suggestion': 'æ‚¨å¯ä»¥å°è¯•åœ¨çº¿æŸ¥çœ‹è¯¥æ–‡çŒ®'
    }), 404


# ============== çŸ¥è¯†åº“ä¿¡æ¯ ==============

@api.route('/kb_info', methods=['GET'])
def kb_info():
    """è·å–çŸ¥è¯†åº“ä¿¡æ¯"""
    try:
        from backend.repositories.vector_repository import VectorRepository, CommunityVectorRepository
        
        vector_repo = VectorRepository()
        community_repo = CommunityVectorRepository()
        
        literature_count = vector_repo.get_count()
        community_count = community_repo.get_count()
        
        return jsonify({
            "success": True,
            "kb_size": literature_count + community_count,
            "source_stats": {
                "neo4j": False,
                "chromadb": True
            },
            "collections": {
                "literature": literature_count,
                "community": community_count
            }
        })
        
    except Exception as e:
        logger.error(f"è·å–çŸ¥è¯†åº“ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500


# ============== ç¿»è¯‘æœåŠ¡ ==============

@api.route('/translate', methods=['POST'])
def translate():
    """
    ç¿»è¯‘æ–‡æœ¬
    
    è¯·æ±‚ä½“:
    {
        "texts": ["text1", "text2", ...]
    }
    """
    try:
        data = request.get_json()
        texts = data.get('texts', [])
        
        if not texts:
            return jsonify({'error': 'æ–‡æœ¬åˆ—è¡¨ä¸ºç©º'}), 400
        
        # è·å–LLMæœåŠ¡
        from backend.services import get_llm_service
        llm_service = get_llm_service()
        
        # ç¿»è¯‘æ¯ä¸ªæ–‡æœ¬
        translations = []
        for text in texts:
            if not text or not text.strip():
                translations.append("")
                continue
            
            try:
                # æ„å»ºç¿»è¯‘æç¤º
                from langchain_core.messages import HumanMessage, SystemMessage
                messages = [
                    SystemMessage(content="ä½ æ˜¯ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡ç¿»è¯‘ä¸“å®¶ã€‚è¯·å°†è‹±æ–‡æ–‡çŒ®ç¿»è¯‘æˆå‡†ç¡®ã€æµç•…çš„ä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®æ€§ã€‚"),
                    HumanMessage(content=f"è¯·å°†ä»¥ä¸‹è‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ï¼š\n\n{text}\n\nè¦æ±‚ï¼š\n1. åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦æ·»åŠ ä»»ä½•è¯´æ˜ã€æ³¨é‡Šæˆ–è§£é‡Š\n2. ä¸è¦è¾“å‡ºå…³äºç¿»è¯‘è§„èŒƒã€ç¿»è¯‘ç‰¹ç‚¹çš„è¯´æ˜\n3. ä¿æŒä¸“ä¸šæœ¯è¯­å‡†ç¡®ï¼Œè¯‘æ–‡é€šé¡º")
                ]
                
                # è°ƒç”¨LLM
                response = llm_service.invoke(messages)
                translation = response.content.strip()
                translations.append(translation)
                
            except Exception as e:
                logger.error(f"ç¿»è¯‘å¤±è´¥: {e}")
                translations.append(f"ç¿»è¯‘å¤±è´¥: {str(e)}")
        
        return jsonify({
            'translations': translations,
            'success': True
        })
        
    except Exception as e:
        logger.error(f"ç¿»è¯‘æœåŠ¡é”™è¯¯: {e}")
        return jsonify({'error': str(e)}), 500


# ============== å¥åº·æ£€æŸ¥ ==============

@api.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥"""
    services = get_services()
    
    status = {
        "status": "healthy" if all([
            services['llm'] is not None,
            services['neo4j'] is not None,
            services['vector'] is not None
        ]) else "degraded",
        "services": {
            "llm": services['llm'] is not None,
            "neo4j": services['neo4j'] is not None,
            "vector": services['vector'] is not None,
            "router": services['router'] is not None,
            "query": services['query'] is not None,
            "semantic": services['semantic'] is not None
        },
        "version": "1.0.0"
    }
    
    return jsonify(status)


# ============== è·¯ç”±ç«¯ç‚¹ ==============

@api.route('/route', methods=['POST'])
def route_question():
    """è·¯ç”±æŸ¥è¯¢åˆ°åˆé€‚çš„ä¸“å®¶ç³»ç»Ÿ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify(ErrorResponse(
                error="è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º",
                code="INVALID_REQUEST"
            ).to_dict()), 400
        
        req = RouteRequest(question=data.get('question', ''))
        errors = req.validate()
        if errors:
            return jsonify(ErrorResponse(
                error="; ".join(errors),
                code="VALIDATION_ERROR"
            ).to_dict()), 400
        
        services = get_services()
        result = services['router'].route(req.question)
        
        return jsonify(RouteResponse(
            primary_expert=result.get('primary_expert', ''),
            confidence=result.get('confidence', 0.0),
            reasoning=result.get('reasoning', ''),
            secondary_expert=result.get('secondary_expert'),
            query_type=result.get('query_type'),
            suggested_keywords=result.get('suggested_keywords', [])
        ).to_dict())
        
    except Exception as e:
        logger.error(f"è·¯ç”±å¤±è´¥: {e}")
        return jsonify(ErrorResponse(
            error=str(e),
            code="ROUTE_ERROR"
        ).to_dict()), 500


# ============== æŸ¥è¯¢ç«¯ç‚¹ ==============

@api.route('/query', methods=['POST'])
def execute_query():
    """æ‰§è¡ŒæŸ¥è¯¢"""
    try:
        data = request.get_json()
        if not data:
            return jsonify(ErrorResponse(
                error="è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º",
                code="INVALID_REQUEST"
            ).to_dict()), 400
        
        question = data.get('question', '')
        expert = data.get('expert')
        top_k = data.get('top_k', 10)
        
        if not question:
            return jsonify(ErrorResponse(
                error="é—®é¢˜ä¸èƒ½ä¸ºç©º",
                code="VALIDATION_ERROR"
            ).to_dict()), 400
        
        services = get_services()
        
        if expert is None:
            route_result = services['router'].route(question)
            expert = route_result.get('primary_expert', 'literature')
        
        if expert == 'neo4j':
            result = services['query'].execute_query(question)
            expert_type = "neo4j"
        else:
            result = services['semantic'].search(question, top_k=top_k)
            expert_type = "literature"
        
        if result.get('success'):
            response = QueryResponse(
                success=True,
                answer=f"æ‰¾åˆ° {result.get('result_count', 0)} æ¡ç»“æœ",
                expert_type=expert_type,
                sources=result.get('materials', []) or result.get('documents', []),
                metadata={
                    "question": question,
                    "expert": expert,
                    "cypher_query": result.get('cypher_query'),
                    "search_query": result.get('search_query')
                }
            )
        else:
            response = QueryResponse(
                success=False,
                answer=f"æŸ¥è¯¢å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}",
                expert_type=expert_type,
                error=result.get('error')
            )
        
        return jsonify(response.to_dict())
        
    except Exception as e:
        logger.error(f"æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify(ErrorResponse(
            error=str(e),
            code="QUERY_ERROR"
        ).to_dict()), 500


# ============== ç²¾ç¡®æŸ¥è¯¢ç«¯ç‚¹ ==============

@api.route('/query/material', methods=['POST'])
def query_material():
    """ææ–™ç²¾ç¡®æŸ¥è¯¢"""
    try:
        data = request.get_json()
        if not data:
            return jsonify(ErrorResponse(
                error="è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º",
                code="INVALID_REQUEST"
            ).to_dict()), 400
        
        property_name = data.get('property', '')
        threshold = data.get('threshold', 0)
        comparison = data.get('comparison', '>')
        limit = data.get('limit', 100)
        
        if not property_name:
            return jsonify(ErrorResponse(
                error="å±æ€§åä¸èƒ½ä¸ºç©º",
                code="VALIDATION_ERROR"
            ).to_dict()), 400
        
        services = get_services()
        materials = services['query'].query_by_property(
            property_name=property_name,
            threshold=threshold,
            comparison=comparison,
            limit=limit
        )
        
        return jsonify({
            "success": True,
            "property": property_name,
            "threshold": threshold,
            "comparison": comparison,
            "materials": materials,
            "count": len(materials)
        })
        
    except Exception as e:
        logger.error(f"ææ–™æŸ¥è¯¢å¤±è´¥: {e}")
        return jsonify(ErrorResponse(
            error=str(e),
            code="QUERY_ERROR"
        ).to_dict()), 500


# ============== è¯­ä¹‰æœç´¢ç«¯ç‚¹ ==============

@api.route('/search', methods=['POST'])
def search_documents():
    """è¯­ä¹‰æœç´¢"""
    try:
        data = request.get_json()
        if not data:
            return jsonify(ErrorResponse(
                error="è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º",
                code="INVALID_REQUEST"
            ).to_dict()), 400
        
        query = data.get('query', '')
        top_k = data.get('top_k', 10)
        collection = data.get('collection', 'literature')
        
        if not query:
            return jsonify(ErrorResponse(
                error="æŸ¥è¯¢ä¸èƒ½ä¸ºç©º",
                code="VALIDATION_ERROR"
            ).to_dict()), 400
        
        services = get_services()
        
        if collection == 'community':
            result = services['vector'].search_community(query, top_k=top_k)
        else:
            result = services['vector'].search_literature(query, top_k=top_k)
        
        return jsonify(SearchResponse(
            success=result.get('success', False),
            query=query,
            documents=result.get('documents', result.get('communities', [])),
            total_count=result.get('total_count', 0),
            search_time_ms=result.get('search_time_ms', 0),
            error=result.get('error')
        ).to_dict())
        
    except Exception as e:
        logger.error(f"æœç´¢å¤±è´¥: {e}")
        return jsonify(ErrorResponse(
            error=str(e),
            code="SEARCH_ERROR"
        ).to_dict()), 500


# ============== èšåˆçŸ¥è¯†ç«¯ç‚¹ ==============

@api.route('/aggregate', methods=['POST'])
def aggregate_knowledge():
    """èšåˆçŸ¥è¯†"""
    try:
        data = request.get_json()
        if not data:
            return jsonify(ErrorResponse(
                error="è¯·æ±‚ä½“ä¸èƒ½ä¸ºç©º",
                code="INVALID_REQUEST"
            ).to_dict()), 400
        
        query = data.get('query', '')
        literature_k = data.get('literature_k', 10)
        community_k = data.get('community_k', 5)
        
        if not query:
            return jsonify(ErrorResponse(
                error="æŸ¥è¯¢ä¸èƒ½ä¸ºç©º",
                code="VALIDATION_ERROR"
            ).to_dict()), 400
        
        services = get_services()
        result = services['vector'].aggregate_knowledge(
            query=query,
            literature_k=literature_k,
            community_k=community_k
        )
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"èšåˆçŸ¥è¯†å¤±è´¥: {e}")
        return jsonify(ErrorResponse(
            error=str(e),
            code="AGGREGATION_ERROR"
        ).to_dict()), 500


# ============== ç»Ÿè®¡ç«¯ç‚¹ ==============

@api.route('/stats', methods=['GET'])
def get_stats():
    """è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯"""
    try:
        services = get_services()
        
        literature_stats = services['vector'].get_collection_stats('literature')
        community_stats = services['vector'].get_collection_stats('community')
        
        return jsonify({
            "success": True,
            "statistics": {
                "literature": {
                    "count": literature_stats.get('count', 0)
                },
                "community": {
                    "count": community_stats.get('count', 0)
                }
            }
        })
        
    except Exception as e:
        logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
        return jsonify(ErrorResponse(
            error=str(e),
            code="STATS_ERROR"
        ).to_dict()), 500


# ============== é”™è¯¯å¤„ç† ==============

@api.errorhandler(404)
def not_found(error):
    """404é”™è¯¯å¤„ç†"""
    return jsonify(ErrorResponse(
        error="è¯·æ±‚çš„èµ„æºä¸å­˜åœ¨",
        code="NOT_FOUND"
    ).to_dict()), 404


@api.errorhandler(500)
def internal_error(error):
    """500é”™è¯¯å¤„ç†"""
    return jsonify(ErrorResponse(
        error="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯",
        code="INTERNAL_ERROR"
    ).to_dict()), 500
