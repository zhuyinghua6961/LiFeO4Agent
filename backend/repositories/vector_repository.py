"""
å‘é‡æ•°æ®åº“è®¿é—®å±‚
å°è£… ChromaDB æ“ä½œ
"""
from typing import Dict, List, Any, Optional
import logging

from backend.config.settings import settings

logger = logging.getLogger(__name__)

try:
    import chromadb
    from chromadb.config import Settings
    CHROMA_AVAILABLE = True
except ImportError:
    CHROMA_AVAILABLE = False
    logger.warning("ChromaDB æœªå®‰è£…")


class VectorRepository:
    """ChromaDB å‘é‡æ•°æ®åº“è®¿é—®ç±»"""
    
    def __init__(self, collection_name: str = "lfp_papers_v3"):
        """
        åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        
        Args:
            collection_name: é›†åˆåç§°ï¼ˆé»˜è®¤ä½¿ç”¨æ®µè½çº§åˆ«çš„ v3 ç‰ˆæœ¬ï¼‰
        """
        if not CHROMA_AVAILABLE:
            raise ImportError("ChromaDB æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…: pip install chromadb")
        
        self._client = None
        self._collection = None
        self._collection_name = collection_name
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯"""
        try:
            self._client = chromadb.PersistentClient(
                path=settings.vector_db_path,
                settings=Settings(anonymized_telemetry=False)
            )
            
            # è·å–é›†åˆï¼ˆä¸ä½¿ç”¨embedding functionï¼Œå› ä¸ºæ•°æ®å·²ç»åŒ…å«é¢„è®¡ç®—çš„embeddingï¼‰
            self._collection = self._client.get_collection(
                name=self._collection_name
            )
            
            logger.info(f"ğŸ“‚ æ®µè½çº§å‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"   è·¯å¾„: {settings.vector_db_path}")
            logger.info(f"   Collection: {self._collection_name}")
            logger.info(f"   æ–‡æ¡£æ•°é‡: {self._collection.count():,}")
            
        except Exception as e:
            logger.error(f"âŒ ChromaDB è¿æ¥å¤±è´¥: {e}")
            raise
    
    def search(
        self, 
        query: str = None,
        query_embedding: List[float] = None,
        n_results: int = 10,
        where_filter: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        è¯­ä¹‰æœç´¢ï¼ˆæ”¯æŒæ®µè½çº§åˆ«æ£€ç´¢å’Œ DOI å»é‡ï¼‰
        
        Args:
            query: æœç´¢æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¦‚æœæä¾›query_embeddingåˆ™å¿½ç•¥ï¼‰
            query_embedding: æŸ¥è¯¢çš„embeddingå‘é‡ï¼ˆ1024ç»´ï¼‰
            n_results: è¿”å›ç»“æœæ•°é‡
            where_filter: è¿‡æ»¤æ¡ä»¶
            
        Returns:
            æœç´¢ç»“æœï¼ˆåŒ…å« documents, metadatas, distancesï¼‰
            æ³¨æ„ï¼šæ®µè½çº§åˆ«æ•°æ®åº“ä¼šè‡ªåŠ¨æŒ‰ DOI å»é‡ï¼Œè¿”å›æ¯ç¯‡æ–‡çŒ®çš„æœ€ç›¸å…³æ®µè½
        """
        try:
            # å¦‚æœæ²¡æœ‰æä¾›embeddingï¼Œè¿”å›é”™è¯¯
            if query_embedding is None:
                return {
                    "success": False,
                    "error": "éœ€è¦æä¾› query_embedding å‚æ•°ï¼ˆ1024ç»´å‘é‡ï¼‰",
                    "documents": [],
                    "metadatas": [],
                    "distances": [],
                    "ids": []
                }
            
            # æŸ¥è¯¢æ›´å¤šç»“æœç”¨äºå»é‡ï¼ˆæ®µè½çº§åˆ«æ•°æ®åº“éœ€è¦ï¼‰
            fetch_count = n_results * 3  # è·å–3å€æ•°é‡ç”¨äºå»é‡
            
            result = self._collection.query(
                query_embeddings=[query_embedding],
                n_results=fetch_count,
                where=where_filter
            )
            
            # æå–ç»“æœ
            documents = result.get("documents", [[]])[0]
            metadatas = result.get("metadatas", [[]])[0]
            distances = result.get("distances", [[]])[0]
            ids = result.get("ids", [[]])[0]
            
            # æŒ‰ DOI å»é‡ï¼ˆä¿ç•™æ¯ä¸ª DOI çš„æœ€ç›¸å…³æ®µè½ï¼‰
            seen_dois = set()
            deduped_docs = []
            deduped_metas = []
            deduped_dists = []
            deduped_ids = []
            
            for i in range(len(documents)):
                meta = metadatas[i]
                doi = meta.get('doi', 'unknown')
                
                # å¦‚æœæ‰€æœ‰æ–‡æ¡£éƒ½æ˜¯ unknown_doiï¼Œåˆ™ä¸è¿›è¡ŒDOIå»é‡
                # å¦åˆ™è·³è¿‡ unknown_doi æ–‡æ¡£
                if doi == 'unknown_doi':
                    # æ£€æŸ¥æ˜¯å¦æ‰€æœ‰æ–‡æ¡£éƒ½æ˜¯ unknown_doi
                    all_unknown = all(m.get('doi') == 'unknown_doi' for m in metadatas)
                    if not all_unknown:
                        continue  # åªæœ‰åœ¨æœ‰å…¶ä»–æœ‰æ•ˆDOIæ—¶æ‰è·³è¿‡
                
                # å»é‡ï¼šæ¯ä¸ª DOI åªä¿ç•™ç¬¬ä¸€ä¸ªï¼ˆæœ€ç›¸å…³çš„ï¼‰æ®µè½
                # ä½†å¦‚æœDOIæ˜¯ unknown_doiï¼Œåˆ™ä¸å»é‡ï¼ˆå› ä¸ºæ— æ³•åŒºåˆ†ï¼‰
                if doi == 'unknown_doi' or doi not in seen_dois:
                    if doi != 'unknown_doi':
                        seen_dois.add(doi)
                    deduped_docs.append(documents[i])
                    deduped_metas.append(meta)
                    deduped_dists.append(distances[i])
                    deduped_ids.append(ids[i])
                    
                    # è¾¾åˆ°ç›®æ ‡æ•°é‡å°±åœæ­¢
                    if len(deduped_docs) >= n_results:
                        break
            
            return {
                "success": True,
                "documents": deduped_docs,
                "metadatas": deduped_metas,
                "distances": deduped_dists,
                "ids": deduped_ids
            }
            
        except Exception as e:
            logger.error(f"å‘é‡æœç´¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "documents": [],
                "metadatas": [],
                "distances": [],
                "ids": []
            }
    
    def search_with_filter(
        self,
        query: str,
        n_results: int = 10,
        property_filter: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        å¸¦å±æ€§è¿‡æ»¤çš„æœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            n_results: è¿”å›æ•°é‡
            property_filter: å±æ€§è¿‡æ»¤æ¡ä»¶
            
        Returns:
            æœç´¢ç»“æœ
        """
        # æ„å»º ChromaDB where è¿‡æ»¤æ¡ä»¶
        where_filter = None
        if property_filter:
            where_filter = {}
            for key, value in property_filter.items():
                where_filter[key] = {"$eq": value}
        
        return self.search(query, n_results, where_filter)
    
    def get_by_doi(self, doi: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ® DOI è·å–æ–‡æ¡£ï¼ˆæ®µè½çº§åˆ«æ•°æ®åº“ä¼šè¿”å›æ‰€æœ‰ç›¸å…³æ®µè½ï¼‰
        
        Args:
            doi: æ–‡çŒ® DOI
            
        Returns:
            æ–‡æ¡£ä¿¡æ¯åˆ—è¡¨æˆ– Noneï¼ˆv2 ç‰ˆæœ¬è¿”å›å¤šä¸ªæ®µè½ï¼‰
        """
        try:
            result = self._collection.get(
                where={"doi": doi},
                limit=100  # é™åˆ¶è¿”å›æ®µè½æ•°é‡
            )
            
            if result and result.get("ids"):
                # è¿”å›æ‰€æœ‰æ®µè½
                return {
                    "ids": result["ids"],
                    "documents": result["documents"],
                    "metadatas": result["metadatas"],
                    "count": len(result["ids"])
                }
            return None
            
        except Exception as e:
            logger.error(f"è·å– DOI æ–‡æ¡£å¤±è´¥: {e}")
            return None
    
    def get_chunk_by_id(self, chunk_id: str) -> Optional[Dict[str, Any]]:
        """
        æ ¹æ® chunk_id è·å–å•ä¸ªæ®µè½
        
        Args:
            chunk_id: æ®µè½ID
            
        Returns:
            æ®µè½ä¿¡æ¯æˆ– None
        """
        try:
            if not chunk_id:
                return None
            
            result = self._collection.get(
                ids=[chunk_id],
                include=["documents", "metadatas"]
            )
            
            if result and result.get("ids"):
                return {
                    "id": result["ids"][0],
                    "document": result["documents"][0],
                    "metadata": result["metadatas"][0]
                }
            return None
            
        except Exception as e:
            logger.error(f"è·å–æ®µè½å¤±è´¥ ({chunk_id}): {e}")
            return None
    
    def get_chunk_with_context(
        self, 
        chunk_id: str, 
        window: int = 2
    ) -> Dict[str, Any]:
        """
        è·å–æ®µè½åŠå…¶ä¸Šä¸‹æ–‡ï¼ˆV3æ–°åŠŸèƒ½ï¼‰
        
        Args:
            chunk_id: æ®µè½ID
            window: ä¸Šä¸‹æ–‡çª—å£å¤§å°ï¼ˆå‰åå„windowä¸ªæ®µè½ï¼‰
            
        Returns:
            åŒ…å«ä¸»æ®µè½å’Œä¸Šä¸‹æ–‡çš„å®Œæ•´ä¿¡æ¯
        """
        try:
            # è·å–ä¸»æ®µè½
            main_chunk = self.get_chunk_by_id(chunk_id)
            if not main_chunk:
                return {
                    "success": False,
                    "error": f"æ®µè½ä¸å­˜åœ¨: {chunk_id}"
                }
            
            metadata = main_chunk["metadata"]
            
            # æ”¶é›†ä¸Šä¸‹æ–‡æ®µè½
            context_chunks = []
            
            # å‘å‰è·å–
            current_id = chunk_id
            for i in range(window):
                prev_id = metadata.get("prev_chunk_id") if i == 0 else context_chunks[0]["metadata"].get("prev_chunk_id")
                if prev_id:
                    prev_chunk = self.get_chunk_by_id(prev_id)
                    if prev_chunk:
                        context_chunks.insert(0, prev_chunk)
                        metadata = prev_chunk["metadata"]
                    else:
                        break
                else:
                    break
            
            # æ·»åŠ ä¸»æ®µè½
            main_index = len(context_chunks)
            context_chunks.append(main_chunk)
            
            # å‘åè·å–
            metadata = main_chunk["metadata"]
            for i in range(window):
                next_id = metadata.get("next_chunk_id") if i == 0 else context_chunks[-1]["metadata"].get("next_chunk_id")
                if next_id:
                    next_chunk = self.get_chunk_by_id(next_id)
                    if next_chunk:
                        context_chunks.append(next_chunk)
                        metadata = next_chunk["metadata"]
                    else:
                        break
                else:
                    break
            
            # ç»„åˆå®Œæ•´æ–‡æœ¬
            full_text = " ".join([chunk["document"] for chunk in context_chunks])
            
            # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯
            main_meta = main_chunk["metadata"]
            context_info = {
                "success": True,
                "main_chunk_id": chunk_id,
                "full_text": full_text,
                "main_text": main_chunk["document"],
                "context_chunks": len(context_chunks),
                "main_chunk_index": main_index,
                "metadata": main_meta,
                "context_range": {
                    "start_page": context_chunks[0]["metadata"].get("page"),
                    "end_page": context_chunks[-1]["metadata"].get("page"),
                    "start_chunk_global": context_chunks[0]["metadata"].get("chunk_index_global"),
                    "end_chunk_global": context_chunks[-1]["metadata"].get("chunk_index_global"),
                }
            }
            
            return context_info
            
        except Exception as e:
            logger.error(f"è·å–ä¸Šä¸‹æ–‡å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_count(self) -> int:
        """è·å–æ–‡æ¡£æ€»æ•°"""
        try:
            return self._collection.count()
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£æ•°é‡å¤±è´¥: {e}")
            return 0
    
    def get_all_documents(self, limit: int = 10000) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ–‡æ¡£ï¼ˆç”¨äºå…³é”®è¯åŒ¹é…é™çº§æ–¹æ¡ˆï¼‰
        
        Args:
            limit: é™åˆ¶æ•°é‡
            
        Returns:
            æ–‡æ¡£åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« text å’Œ metadata
        """
        try:
            result = self._collection.get(limit=limit, include=["documents", "metadatas"])
            docs = []
            for i, doc in enumerate(result.get("documents", [])):
                docs.append({
                    "text": doc,
                    "metadata": result.get("metadatas", [{}])[i]
                })
            return docs
        except Exception as e:
            logger.error(f"è·å–æ‰€æœ‰æ–‡æ¡£å¤±è´¥: {e}")
            return []
    
    def get_all_metadata(self, limit: int = 1000) -> List[Dict]:
        """
        è·å–æ‰€æœ‰æ–‡æ¡£çš„å…ƒæ•°æ®ï¼ˆå…¼å®¹æ–°æ—§å…ƒæ•°æ®æ ¼å¼ï¼‰
        
        Args:
            limit: é™åˆ¶æ•°é‡
            
        Returns:
            å…ƒæ•°æ®åˆ—è¡¨ï¼ˆè‡ªåŠ¨å…¼å®¹ source_file å’Œ filename å­—æ®µï¼‰
        """
        try:
            result = self._collection.get(limit=limit)
            metadatas = result.get("metadatas", [])
            
            # æ ‡å‡†åŒ–å…ƒæ•°æ®å­—æ®µï¼ˆå…¼å®¹æ–°æ—§æ ¼å¼ï¼‰
            normalized = []
            for meta in metadatas:
                # ç»Ÿä¸€ä½¿ç”¨ filename å­—æ®µ
                if 'source_file' in meta and 'filename' not in meta:
                    meta['filename'] = meta['source_file']
                elif 'filename' in meta and 'source_file' not in meta:
                    meta['source_file'] = meta['filename']
                normalized.append(meta)
            
            return normalized
        except Exception as e:
            logger.error(f"è·å–å…ƒæ•°æ®å¤±è´¥: {e}")
            return []
    
    def add_documents(
        self,
        documents: List[str],
        metadatas: List[Dict],
        ids: List[str]
    ) -> bool:
        """
        æ·»åŠ æ–‡æ¡£
        
        Args:
            documents: æ–‡æ¡£å†…å®¹åˆ—è¡¨
            metadatas: å…ƒæ•°æ®åˆ—è¡¨
            ids: ID åˆ—è¡¨
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            self._collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )
            logger.info(f"âœ… æ·»åŠ  {len(documents)} ä¸ªæ–‡æ¡£")
            return True
        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def delete_by_doi(self, doi: str) -> bool:
        """
        æ ¹æ® DOI åˆ é™¤æ–‡æ¡£
        
        Args:
            doi: æ–‡çŒ® DOI
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            self._collection.delete(
                where={"doi": doi}
            )
            logger.info(f"âœ… åˆ é™¤ DOI ä¸º {doi} çš„æ–‡æ¡£")
            return True
        except Exception as e:
            logger.error(f"åˆ é™¤æ–‡æ¡£å¤±è´¥: {e}")
            return False
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self._client:
            self._client.close()


class CommunityVectorRepository:
    """ç¤¾åŒºæ‘˜è¦å‘é‡æ•°æ®åº“è®¿é—®ç±»"""
    
    def __init__(self, collection_name: str = "communities"):
        """åˆå§‹åŒ–ç¤¾åŒºå‘é‡æ•°æ®åº“"""
        if not CHROMA_AVAILABLE:
            raise ImportError("ChromaDB æœªå®‰è£…")
        
        self._client = None
        self._collection = None
        self._collection_name = collection_name
        self._init_client()
    
    def _init_client(self):
        """åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯"""
        try:
            self._client = chromadb.PersistentClient(
                path=settings.community_vector_db_path,
                settings=Settings(anonymized_telemetry=False)
            )
            
            self._collection = self._client.get_or_create_collection(
                name=self._collection_name,
                metadata={"hnsw:space": "cosine"}
            )
            
            logger.info(f"ğŸ“‚ ç¤¾åŒºå‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")
            logger.info(f"   è·¯å¾„: {settings.community_vector_db_path}")
            logger.info(f"   Collection: {self._collection_name}")
            logger.info(f"   æ–‡æ¡£æ•°é‡: {self._collection.count():,}")
            
        except Exception as e:
            logger.error(f"âŒ ç¤¾åŒºå‘é‡åº“è¿æ¥å¤±è´¥: {e}")
            raise
    
    def search(
        self, 
        query: str, 
        n_results: int = 10
    ) -> Dict[str, Any]:
        """æœç´¢ç¤¾åŒºæ‘˜è¦"""
        try:
            result = self._collection.query(
                query_texts=[query],
                n_results=n_results
            )
            
            return {
                "success": True,
                "documents": result.get("documents", [[]])[0],
                "metadatas": result.get("metadatas", [[]])[0],
                "distances": result.get("distances", [[]])[0],
                "ids": result.get("ids", [[]])[0]
            }
            
        except Exception as e:
            logger.error(f"ç¤¾åŒºæ‘˜è¦æœç´¢å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "documents": [],
                "metadatas": [],
                "distances": []
            }
    
    def get_count(self) -> int:
        """è·å–æ–‡æ¡£æ€»æ•°"""
        try:
            return self._collection.count()
        except Exception as e:
            logger.error(f"è·å–æ–‡æ¡£æ•°é‡å¤±è´¥: {e}")
            return 0
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self._client:
            self._client.close()


# åˆ›å»ºå…¨å±€å®ä¾‹
_vector_repo: Optional[VectorRepository] = None
_community_repo: Optional[CommunityVectorRepository] = None


def get_vector_repository() -> VectorRepository:
    """è·å–å…¨å±€ Vector Repository å®ä¾‹"""
    global _vector_repo
    if _vector_repo is None:
        _vector_repo = VectorRepository()
    return _vector_repo


def get_community_repository() -> CommunityVectorRepository:
    """è·å–å…¨å±€ Community Repository å®ä¾‹"""
    global _community_repo
    if _community_repo is None:
        _community_repo = CommunityVectorRepository()
    return _community_repo
