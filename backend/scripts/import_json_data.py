#!/usr/bin/env python3
"""
å¯¼å…¥ json/ ç›®å½•çš„æ–‡çŒ®æ‘˜è¦æ•°æ®åˆ° ChromaDB
"""
import json
import os
from pathlib import Path
import chromadb
from chromadb.config import Settings

# ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
VECTOR_DB_PATH = os.getenv("VECTOR_DB_PATH", str(Path(__file__).parent.parent.parent / "vector_database"))


def import_json_data(json_dir: str, collection_name: str = "literature"):
    """
    ä» json ç›®å½•å¯¼å…¥æ•°æ®åˆ° ChromaDB
    
    Args:
        json_dir: json æ–‡ä»¶ç›®å½•
        collection_name: ChromaDB é›†åˆåç§°
    """
    print(f"ğŸ“ æ•°æ®æºç›®å½•: {json_dir}")
    print(f"ğŸ“ ChromaDB è·¯å¾„: {VECTOR_DB_PATH}")
    print(f"ğŸ“¦ é›†åˆåç§°: {collection_name}")
    print("-" * 50)
    
    # è·å–æ‰€æœ‰ json æ–‡ä»¶
    json_files = [f for f in os.listdir(json_dir) if f.endswith('.json')]
    print(f"ğŸ“„ æ‰¾åˆ° {len(json_files)} ä¸ª JSON æ–‡ä»¶")
    
    if len(json_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ° JSON æ–‡ä»¶")
        return
    
    # åˆå§‹åŒ– ChromaDB
    print("\nğŸ”Œ è¿æ¥ ChromaDB...")
    client = chromadb.PersistentClient(
        path=VECTOR_DB_PATH,
        settings=Settings(anonymized_telemetry=False)
    )
    
    # å…ˆåˆ é™¤æ—§é›†åˆï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    try:
        client.delete_collection(collection_name)
        print(f"ğŸ—‘ï¸  å·²åˆ é™¤æ—§é›†åˆ: {collection_name}")
    except Exception:
        pass
    
    # åˆ›å»ºæ–°é›†åˆ
    collection = client.create_collection(
        name=collection_name,
        metadata={"hnsw:space": "cosine"}
    )
    count_before = 0
    
    # å¯¼å…¥æ•°æ®
    documents = []
    metadatas = []
    embeddings = []
    ids = []
    
    total_items = 0
    batch_size = 50
    
    for i, json_file in enumerate(sorted(json_files)):
        filepath = os.path.join(json_dir, json_file)
        
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # å¤„ç†æ•°æ®ï¼ˆå¯èƒ½æ˜¯åˆ—è¡¨æˆ–å•ä¸ªå¯¹è±¡ï¼‰
            if isinstance(data, list):
                items = data
            else:
                items = [data]
            
            for item in items:
                text = item.get('text', '')
                embedding = item.get('embedding', [])
                metadata = item.get('metadata', {})
                
                if not text or not embedding:
                    continue
                
                # ç”Ÿæˆ IDï¼ˆä½¿ç”¨æ–‡ä»¶åä½œä¸ºåŸºç¡€ï¼‰
                doc_id = f"{Path(json_file).stem}_{total_items}"
                
                documents.append(text)
                embeddings.append(embedding)
                metadatas.append({
                    **metadata,
                    'source_file': json_file,
                    'imported_at': str(os.path.getmtime(__file__))
                })
                ids.append(doc_id)
                total_items += 1
            
            # æ‰¹é‡å¯¼å…¥
            if total_items >= batch_size:
                print(f"  å¯¼å…¥è¿›åº¦: {i+1}/{len(json_files)} ({total_items} æ¡)")
                collection.add(
                    documents=documents,
                    embeddings=embeddings,
                    metadatas=metadatas,
                    ids=ids
                )
                documents = []
                metadatas = []
                embeddings = []
                ids = []
                
        except Exception as e:
            print(f"  âš ï¸ å¤„ç†æ–‡ä»¶ {json_file} å¤±è´¥: {e}")
            continue
    
    # å¯¼å…¥å‰©ä½™æ•°æ®
    if documents:
        collection.add(
            documents=documents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=ids
        )
    
    print("-" * 50)
    count_after = collection.count()
    print(f"âœ… å¯¼å…¥å®Œæˆ!")
    print(f"   å¯¼å…¥å‰æ–‡æ¡£æ•°: {count_before}")
    print(f"   å¯¼å…¥åæ–‡æ¡£æ•°: {count_after}")
    print(f"   æ–°å¢æ–‡æ¡£æ•°: {count_after - count_before}")
    
    client.close()


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¯¼å…¥ JSON æ•°æ®åˆ° ChromaDB')
    parser.add_argument('--json_dir', type=str, default='../../../json',
                        help='JSON æ–‡ä»¶ç›®å½•')
    parser.add_argument('--collection', type=str, default='literature',
                        help='ChromaDB é›†åˆåç§°')
    
    args = parser.parse_args()
    
    # è½¬æ¢ç›¸å¯¹è·¯å¾„ä¸ºç»å¯¹è·¯å¾„ï¼ˆä» backend/scripts å¼€å§‹ï¼‰
    json_dir = Path(__file__).parent.parent.parent / args.json_dir
    json_dir = json_dir.resolve()
    
    import_json_data(str(json_dir), args.collection)


if __name__ == '__main__':
    main()
