#!/usr/bin/env python3
"""
Marker PDFè½¬æ¢æœåŠ¡
ç«¯å£: 8002

ä¼˜åŒ–ç‰ˆæœ¬ï¼ˆé˜²å†…å­˜æ³„éœ²ï¼‰ï¼š
- æœåŠ¡å¯åŠ¨æ—¶é¢„åŠ è½½æ¨¡å‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰
- æ”¯æŒå•ä¸ªå’Œæ‰¹é‡PDFè½¬æ¢
- ä¸¥æ ¼çš„å¹¶å‘æ§åˆ¶ï¼ˆä¸²è¡Œå¤„ç†ï¼‰
- å®Œå–„çš„é”™è¯¯å¤„ç†å’Œèµ„æºç®¡ç†
- æ¯æ¬¡è½¬æ¢åå¼ºåˆ¶æ¸…ç†å†…å­˜
- å®šæœŸè‡ªåŠ¨é‡å¯æœºåˆ¶
"""

from flask import Flask, request, jsonify
from flask_cors import CORS
import tempfile
import os
import time
import logging
from datetime import datetime
import threading
from pathlib import Path
import gc
import psutil

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # å…è®¸è·¨åŸŸè¯·æ±‚

# å…¨å±€æ¨¡å‹å’Œè½¬æ¢å™¨å˜é‡
model_dict = None
converter = None
model_load_time = None
model_lock = threading.Lock()

# å†…å­˜ç›‘æ§å˜é‡
conversion_count = 0
start_time = time.time()
MAX_CONVERSIONS = 50  # å¤„ç†50ä¸ªPDFåè‡ªåŠ¨é‡å¯
MEMORY_THRESHOLD_GB = 8.0  # å†…å­˜è¶…è¿‡8GBæ—¶è­¦å‘Š

def load_models():
    """åŠ è½½Markeræ¨¡å‹å’Œè½¬æ¢å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    global model_dict, converter, model_load_time
    
    if converter is not None:
        return converter
    
    with model_lock:
        # åŒé‡æ£€æŸ¥
        if converter is not None:
            return converter
        
        try:
            logger.info("ğŸ”„ æ­£åœ¨åŠ è½½Markeræ¨¡å‹...")
            start_time = time.time()
            
            from marker.models import create_model_dict
            from marker.converters.pdf import PdfConverter
            
            # åˆ›å»ºæ¨¡å‹å­—å…¸
            model_dict = create_model_dict()
            
            # åˆ›å»ºè½¬æ¢å™¨ (renderer å‚æ•°åº”è¯¥æ˜¯å­—ç¬¦ä¸²ç±»å)
            converter = PdfConverter(
                artifact_dict=model_dict,
                renderer="marker.renderers.markdown.MarkdownRenderer"
            )
            
            model_load_time = datetime.now().isoformat()
            load_duration = time.time() - start_time
            
            logger.info(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼è€—æ—¶: {load_duration:.1f}ç§’")
            return converter
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            logger.error(traceback.format_exc())
            raise

conversion_lock = threading.Semaphore(1)  # é™åˆ¶å¹¶å‘è½¬æ¢æ•°é‡ï¼ˆä¸²è¡Œå¤„ç†ï¼Œé¿å…æ¨¡å‹å†²çªï¼‰


def get_memory_usage():
    """è·å–å½“å‰è¿›ç¨‹å†…å­˜ä½¿ç”¨ï¼ˆGBï¼‰"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / (1024 ** 3)


def cleanup_memory():
    """å¼ºåˆ¶æ¸…ç†å†…å­˜"""
    try:
        # æ¸…ç† Python åƒåœ¾å›æ”¶
        gc.collect()
        
        # æ¸…ç† PyTorch CUDA ç¼“å­˜
        try:
            import torch
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
        except:
            pass
        
        logger.debug("âœ“ å†…å­˜æ¸…ç†å®Œæˆ")
    except Exception as e:
        logger.warning(f"å†…å­˜æ¸…ç†å¤±è´¥: {e}")


def check_memory_and_restart():
    """æ£€æŸ¥å†…å­˜ä½¿ç”¨ï¼Œå¿…è¦æ—¶è§¦å‘é‡å¯"""
    global conversion_count
    
    mem_usage = get_memory_usage()
    uptime = (time.time() - start_time) / 3600  # å°æ—¶
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
    should_restart = False
    reason = ""
    
    if conversion_count >= MAX_CONVERSIONS:
        should_restart = True
        reason = f"å·²å¤„ç† {conversion_count} ä¸ªPDF"
    elif mem_usage > MEMORY_THRESHOLD_GB:
        should_restart = True
        reason = f"å†…å­˜ä½¿ç”¨ {mem_usage:.2f}GB è¶…è¿‡é˜ˆå€¼"
    elif uptime > 10:  # è¿è¡Œè¶…è¿‡10å°æ—¶
        should_restart = True
        reason = f"è¿è¡Œæ—¶é—´ {uptime:.1f}h è¶…è¿‡10å°æ—¶"
    
    if should_restart:
        logger.warning(f"âš ï¸  è§¦å‘è‡ªåŠ¨é‡å¯: {reason}")
        logger.info(f"ğŸ“Š ç»Ÿè®¡: å¤„ç†æ•°={conversion_count}, å†…å­˜={mem_usage:.2f}GB, è¿è¡Œæ—¶é—´={uptime:.1f}h")
        # è¿”å›503è®©ç›‘æ§è„šæœ¬é‡å¯æœåŠ¡
        os._exit(1)


@app.route('/health', methods=['GET'])
def health_check():
    """å¥åº·æ£€æŸ¥æ¥å£"""
    mem_usage = get_memory_usage()
    uptime = (time.time() - start_time) / 3600
    
    return jsonify({
        "status": "healthy",
        "service": "marker-pdf-service",
        "model_loaded": converter is not None,
        "model_load_time": model_load_time,
        "conversion_count": conversion_count,
        "memory_usage_gb": round(mem_usage, 2),
        "uptime_hours": round(uptime, 2),
        "timestamp": datetime.now().isoformat()
    })

@app.route('/api/convert_pdf', methods=['POST'])
def convert_pdf():
    """
    PDFè½¬Markdownæ¥å£
    
    è¯·æ±‚å‚æ•°:
        - file: PDFæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
        - langs: è¯­è¨€åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼Œé»˜è®¤"en,zh"ï¼‰
        - batch_multiplier: æ‰¹å¤„ç†å€æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤2ï¼‰
        - max_pages: æœ€å¤§å¤„ç†é¡µæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤None=å…¨éƒ¨ï¼‰
    
    å“åº”:
        {
            "success": true,
            "markdown": "...",
            "metadata": {
                "pages": 30,
                "processing_time": 95.3
            }
        }
    """
    global conversion_count
    
    start_time = time.time()
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
    check_memory_and_restart()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
    if 'file' not in request.files:
        return jsonify({
            "success": False,
            "error": "ç¼ºå°‘PDFæ–‡ä»¶"
        }), 400
    
    pdf_file = request.files['file']
    
    if pdf_file.filename == '':
        return jsonify({
            "success": False,
            "error": "æ–‡ä»¶åä¸ºç©º"
        }), 400
    
    # è·å–å‚æ•°
    langs = request.form.get('langs', 'en,zh').split(',')
    batch_multiplier = int(request.form.get('batch_multiplier', 2))
    max_pages = request.form.get('max_pages', None)
    if max_pages:
        max_pages = int(max_pages)
    
    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    tmp_file = None
    try:
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:
            pdf_file.save(tmp.name)
            tmp_file = tmp.name
        
        # éªŒè¯ä¸´æ—¶æ–‡ä»¶
        file_size = os.path.getsize(tmp_file)
        logger.info(f"ğŸ“„ å¼€å§‹å¤„ç†PDF: {pdf_file.filename} (å¤§å°: {file_size/1024:.1f} KB)")
        
        # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
        with conversion_lock:
            # åŠ è½½æ¨¡å‹å’Œè½¬æ¢å™¨
            conv = load_models()
            
            # ä½¿ç”¨æ–°APIè½¬æ¢PDFï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
            max_retries = 2
            last_error = None
            
            for attempt in range(max_retries):
                try:
                    rendered = conv(tmp_file)
                    break  # æˆåŠŸåˆ™è·³å‡ºå¾ªç¯
                except RuntimeError as e:
                    last_error = e
                    if "size of tensor" in str(e) and attempt < max_retries - 1:
                        logger.warning(f"âš ï¸ è½¬æ¢å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                        logger.info("ğŸ”„ æ¸…ç†ç¼“å­˜åé‡è¯•...")
                        # å¼ºåˆ¶æ¸…ç†å†…å­˜
                        cleanup_memory()
                        time.sleep(1)  # ç­‰å¾…ä¸€ç§’
                    else:
                        raise
            
            # è½¬æ¢æˆåŠŸåç«‹å³æ¸…ç†å†…å­˜
            cleanup_memory()
        
        processing_time = time.time() - start_time
        
        # å¢åŠ è½¬æ¢è®¡æ•°
        conversion_count += 1
        
        logger.info(f"âœ… PDFå¤„ç†æˆåŠŸ: {pdf_file.filename}, è€—æ—¶: {processing_time:.1f}ç§’ (æ€»è®¡: {conversion_count})")
        
        # æå– markdown æ–‡æœ¬
        markdown_text = rendered.markdown if hasattr(rendered, 'markdown') else str(rendered)
        
        # æ¸…ç† rendered å¯¹è±¡
        del rendered
        gc.collect()
        
        return jsonify({
            "success": True,
            "markdown": markdown_text,
            "metadata": {
                "processing_time": processing_time,
                "filename": pdf_file.filename,
                "conversion_count": conversion_count
            }
        })
    
    except Exception as e:
        processing_time = time.time() - start_time
        error_msg = str(e)
        
        # è¯†åˆ«ä¸åŒç±»å‹çš„é”™è¯¯
        if "PdfiumError" in str(type(e)) or "Failed to load document" in error_msg:
            # è®°å½•æ›´å¤šè¯Šæ–­ä¿¡æ¯
            if tmp_file and os.path.exists(tmp_file):
                file_size = os.path.getsize(tmp_file)
                logger.error(f"âŒ PDFæ–‡ä»¶æ— æ³•è§£æ: {pdf_file.filename} (ä¸´æ—¶æ–‡ä»¶å¤§å°: {file_size} bytes)")
                
                # å°è¯•ç”¨fileå‘½ä»¤æ£€æŸ¥
                try:
                    import subprocess
                    file_output = subprocess.check_output(['file', tmp_file], stderr=subprocess.STDOUT).decode()
                    logger.error(f"   æ–‡ä»¶ç±»å‹æ£€æµ‹: {file_output.strip()}")
                except:
                    pass
            else:
                logger.error(f"âŒ PDFæ–‡ä»¶æ— æ³•è§£æ: {pdf_file.filename} (ä¸´æ—¶æ–‡ä»¶ä¸å­˜åœ¨)")
            
            logger.error(f"   åŸå› : PDFæ–‡ä»¶æŸåã€åŠ å¯†æˆ–æ ¼å¼ä¸æ”¯æŒ")
            error_type = "PDFæ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–å·²æŸå"
        elif "size of tensor" in error_msg:
            logger.error(f"âŒ æ¨¡å‹å¤„ç†å¤±è´¥: {pdf_file.filename}")
            logger.error(f"   åŸå› : å†…éƒ¨æ¨¡å‹é”™è¯¯ï¼ˆå·²å°è¯•é‡è¯•ï¼‰")
            error_type = "æ¨¡å‹å†…éƒ¨é”™è¯¯"
        else:
            logger.error(f"âŒ PDFå¤„ç†å¤±è´¥: {pdf_file.filename}, é”™è¯¯: {e}")
            error_type = "æœªçŸ¥é”™è¯¯"
        
        import traceback
        logger.error(traceback.format_exc())
        
        # å¤±è´¥åä¹Ÿè¦æ¸…ç†å†…å­˜
        cleanup_memory()
        
        return jsonify({
            "success": False,
            "error": error_type,
            "error_detail": error_msg,
            "processing_time": processing_time
        }), 500
    
    finally:
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if tmp_file and os.path.exists(tmp_file):
            try:
                os.unlink(tmp_file)
            except Exception as e:
                logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
        
        # å¼ºåˆ¶åƒåœ¾å›æ”¶
        gc.collect()

@app.route('/api/batch_convert', methods=['POST'])
def batch_convert_pdf():
    """
    æ‰¹é‡PDFè½¬Markdownæ¥å£
    
    è¯·æ±‚å‚æ•°:
        - files: å¤šä¸ªPDFæ–‡ä»¶ï¼ˆå¿…éœ€ï¼‰
        - langs: è¯­è¨€åˆ—è¡¨ï¼Œé€—å·åˆ†éš”ï¼ˆå¯é€‰ï¼Œé»˜è®¤"en,zh"ï¼‰
        - batch_multiplier: æ‰¹å¤„ç†å€æ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤2ï¼‰
        - max_pages: æœ€å¤§å¤„ç†é¡µæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤None=å…¨éƒ¨ï¼‰
    
    å“åº”:
        {
            "success": true,
            "total": 3,
            "succeeded": 2,
            "failed": 1,
            "results": [
                {
                    "filename": "paper1.pdf",
                    "success": true,
                    "markdown": "...",
                    "metadata": {...}
                },
                {
                    "filename": "paper2.pdf",
                    "success": false,
                    "error": "..."
                }
            ]
        }
    """
    global conversion_count
    
    start_time = time.time()
    
    # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡å¯
    check_memory_and_restart()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶
    if 'files' not in request.files:
        return jsonify({
            "success": False,
            "error": "ç¼ºå°‘PDFæ–‡ä»¶"
        }), 400
    
    pdf_files = request.files.getlist('files')
    
    if not pdf_files:
        return jsonify({
            "success": False,
            "error": "æ–‡ä»¶åˆ—è¡¨ä¸ºç©º"
        }), 400
    
    # è·å–å‚æ•°
    langs = request.form.get('langs', 'en,zh').split(',')
    batch_multiplier = int(request.form.get('batch_multiplier', 2))
    max_pages = request.form.get('max_pages', None)
    if max_pages:
        max_pages = int(max_pages)
    
    results = []
    succeeded = 0
    failed = 0
    
    logger.info(f"ğŸ“¦ å¼€å§‹æ‰¹é‡å¤„ç† {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")
    
    # å¤„ç†æ¯ä¸ªæ–‡ä»¶
    for idx, pdf_file in enumerate(pdf_files):
        tmp_file = None
        try:
            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp:
                pdf_file.save(tmp.name)
                tmp_file = tmp.name
            
            logger.info(f"  ğŸ“„ å¤„ç† [{idx+1}/{len(pdf_files)}]: {pdf_file.filename}")
            
            # ä½¿ç”¨ä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
            with conversion_lock:
                # åŠ è½½æ¨¡å‹å’Œè½¬æ¢å™¨
                conv = load_models()
                
                file_start = time.time()
                # ä½¿ç”¨æ–°APIè½¬æ¢ï¼ˆæ·»åŠ é‡è¯•æœºåˆ¶ï¼‰
                max_retries = 2
                last_error = None
                
                for attempt in range(max_retries):
                    try:
                        rendered = conv(tmp_file)
                        break  # æˆåŠŸåˆ™è·³å‡ºå¾ªç¯
                    except RuntimeError as e:
                        last_error = e
                        if "size of tensor" in str(e) and attempt < max_retries - 1:
                            logger.warning(f"  âš ï¸ è½¬æ¢å¤±è´¥ (å°è¯• {attempt + 1}/{max_retries}): {e}")
                            logger.info("  ğŸ”„ æ¸…ç†ç¼“å­˜åé‡è¯•...")
                            # å¼ºåˆ¶æ¸…ç†å†…å­˜
                            cleanup_memory()
                            time.sleep(1)
                        else:
                            raise
                
                file_duration = time.time() - file_start
                
                # è½¬æ¢æˆåŠŸåç«‹å³æ¸…ç†å†…å­˜
                cleanup_memory()
            
            # æå– markdown æ–‡æœ¬
            markdown_text = rendered.markdown if hasattr(rendered, 'markdown') else str(rendered)
            
            # æ¸…ç† rendered å¯¹è±¡
            del rendered
            gc.collect()
            
            results.append({
                "filename": pdf_file.filename,
                "success": True,
                "markdown": markdown_text,
                "metadata": {
                    "processing_time": file_duration
                }
            })
            succeeded += 1
            conversion_count += 1
            logger.info(f"  âœ… å®Œæˆ: {pdf_file.filename}, è€—æ—¶: {file_duration:.1f}ç§’ (æ€»è®¡: {conversion_count})")
            
        except Exception as e:
            error_msg = str(e)
            
            # è¯†åˆ«é”™è¯¯ç±»å‹
            if "PdfiumError" in str(type(e)) or "Failed to load document" in error_msg:
                error_type = "PDFæ–‡ä»¶æ ¼å¼é”™è¯¯æˆ–å·²æŸå"
                logger.error(f"  âŒ PDFæ–‡ä»¶æ— æ³•è§£æ: {pdf_file.filename}")
            elif "size of tensor" in error_msg:
                error_type = "æ¨¡å‹å†…éƒ¨é”™è¯¯"
                logger.error(f"  âŒ æ¨¡å‹å¤„ç†å¤±è´¥: {pdf_file.filename}")
            else:
                error_type = "æœªçŸ¥é”™è¯¯"
                logger.error(f"  âŒ å¤±è´¥: {pdf_file.filename}, é”™è¯¯: {e}")
            
            results.append({
                "filename": pdf_file.filename,
                "success": False,
                "error": error_type,
                "error_detail": error_msg
            })
            failed += 1
            
            # å¤±è´¥åä¹Ÿè¦æ¸…ç†å†…å­˜
            cleanup_memory()
        
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if tmp_file and os.path.exists(tmp_file):
                try:
                    os.unlink(tmp_file)
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
    
    total_time = time.time() - start_time
    logger.info(f"ğŸ“¦ æ‰¹é‡å¤„ç†å®Œæˆ: {succeeded}/{len(pdf_files)} æˆåŠŸ, æ€»è€—æ—¶: {total_time:.1f}ç§’")
    
    return jsonify({
        "success": True,
        "total": len(pdf_files),
        "succeeded": succeeded,
        "failed": failed,
        "results": results,
        "total_processing_time": total_time,
        "total_conversion_count": conversion_count
    })

@app.route('/', methods=['GET'])
def index():
    """ç®€å•çš„çŠ¶æ€é¡µé¢"""
    return jsonify({
        "service": "Marker PDF Service",
        "version": "1.0",
        "endpoints": {
            "health": "GET /health",
            "convert": "POST /api/convert_pdf",
            "batch_convert": "POST /api/batch_convert"
        }
    })

if __name__ == '__main__':
    logger.info("="*60)
    logger.info("Marker PDFè½¬æ¢æœåŠ¡å¯åŠ¨ä¸­...")
    logger.info("="*60)
    
    # é¢„åŠ è½½æ¨¡å‹
    try:
        load_models()
    except Exception as e:
        logger.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼ŒæœåŠ¡å°†æ— æ³•å¤„ç†è¯·æ±‚: {e}")
        logger.warning("âš ï¸ æœåŠ¡ä»ä¼šå¯åŠ¨ï¼Œä½†éœ€è¦åœ¨ç¬¬ä¸€æ¬¡è¯·æ±‚æ—¶åŠ è½½æ¨¡å‹")
    
    logger.info("ğŸ‰ æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
    logger.info("ğŸ“ è®¿é—®åœ°å€: http://0.0.0.0:8002")
    logger.info("ğŸ“ å¥åº·æ£€æŸ¥: http://0.0.0.0:8002/health")
    logger.info("ğŸ“ å•ä¸ªè½¬æ¢: POST http://0.0.0.0:8002/api/convert_pdf")
    logger.info("ğŸ“ æ‰¹é‡è½¬æ¢: POST http://0.0.0.0:8002/api/batch_convert")
    logger.info(f"âš ï¸  è‡ªåŠ¨é‡å¯ç­–ç•¥: å¤„ç†{MAX_CONVERSIONS}ä¸ªPDFæˆ–å†…å­˜>{MEMORY_THRESHOLD_GB}GBæˆ–è¿è¡Œ>10h")
    logger.info("="*60)
    
    # å¯åŠ¨FlaskæœåŠ¡ï¼ˆä½¿ç”¨å•çº¿ç¨‹æ¨¡å¼é¿å…çº¿ç¨‹æ³„éœ²ï¼‰
    from werkzeug.serving import run_simple
    run_simple(
        '0.0.0.0',
        8002,
        app,
        use_reloader=False,
        use_debugger=False,
        threaded=False,  # å•çº¿ç¨‹æ¨¡å¼ï¼Œé¿å…çº¿ç¨‹æ³„éœ²
        processes=1
    )
